### LR 原理

- 分类，经典的二分类算法！
  - 为什么用LR：1.广义模型推导所得 2.满足统计的最大熵模型 3.性质优秀，方便使用（Sigmoid函数是平滑的，而且任意阶可导，一阶二阶导数可以直接由函数值得到不用进行求导，这在实现中很实用）
- 逻辑回归就是这样的一个过程：面对一个回归或者分类问题，建立代价函数，然后通过优化方法迭代求解出最优的模型参数，然后测试验证我们这个求解的模型的好坏。
- Logistic 回归虽然名字里带“回归”，但是它实际上是一种分类方法，主要用于两分类问题（即输出只有两种，分别代表两个类别）
- 回归模型中，y 是一个定性变量，比如 y = 0 或 1，logistic 方法主要应用于研究某些事件发生的概率。
- 逻辑回归的本质：极大似然估计 $$J(w)=-l(w)=-\sum_{i = 1}^n y^{(i)}ln(\phi(z^{(i)})) + (1 - y^{(i)})ln(1-\phi(z^{(i)}))$$
- 逻辑回归的激活函数：Sigmoid $y = \sigma (z) = \frac{1}{1+e^{-z}}$
- 逻辑回归的代价函数：交叉熵



参考资料：
https://github.com/amusi/Deep-Learning-Interview-Book/blob/master/docs/机器学习.md
